{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import pyspark\n",
    "import subprocess\n",
    "import click\n",
    "import traceback\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark import SparkConf, SparkContext\n",
    "\n",
    "def _get_spark_handle():\n",
    "\n",
    "    _spark = pyspark.sql.SparkSession.builder \\\n",
    "            .master(\"local[%d]\" % 2) \\\n",
    "            .appName(\n",
    "            \"Spark Preprocessing\") \\\n",
    "            .config(\"spark.executor.memory\", \"4g\") \\\n",
    "            .config(\"spark.sql.execution.arrow.enable\", \"true\") \\\n",
    "            .config(\"spark.ui.showConsoleProgress\", \"true\") \\\n",
    "            .getOrCreate()\n",
    "\n",
    "    return _spark\n",
    "\n",
    "\n",
    "def _spark_handle():\n",
    "    spark_handle = _get_spark_handle()\n",
    "    return spark_handle\n",
    "\n",
    "\n",
    "def _read_file(path):\n",
    "    df = _spark_handle().read.options().json(path)\n",
    "    return df\n",
    "\n",
    "\n",
    "df = _read_file('/Users/allen.wu/git/kkstream/StepContent__nocontent_title_desc')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+-------+\n",
      "|                 url|               title|               terms|            imageUrl|traffic|\n",
      "+--------------------+--------------------+--------------------+--------------------+-------+\n",
      "|http://www.nbcsan...|Travel Insurance:...|C~Penalty|27714|U...|https://media.nbc...|    151|\n",
      "|https://www.rd.co...|Travel Jokes - Fu...|E~$99|8388|U^^Qua...|                null|   2215|\n",
      "|https://petapixel...|Travel Like a Pho...|E~founder|137935|...|                null|   2033|\n",
      "|https://www.rd.co...|Travel Point Perk...|C~Airline|46569|U...|                null|    897|\n",
      "|https://www.rd.co...|Travel Tips: 10 S...|                null|                null|    183|\n",
      "|https://www.rd.co...|Travel Tips: Avoi...|                null|                null|   1745|\n",
      "|https://www.sfgat...|Travel Troublesho...|C~Want|128004|U^^...|https://s.hdnux.c...|    302|\n",
      "|https://www.sfgat...|Travel Troublesho...|E~Sea Grottoes|6|...|https://s.hdnux.c...|     63|\n",
      "|https://www.sfgat...|Travel Troublesho...|C~Airport|46451|U...|https://s.hdnux.c...|    309|\n",
      "|http://www.fox7au...|Travel Tuesday: C...|T~/travel|179356|...|                null|    124|\n",
      "|https://fox8.com/...|Travel advisory i...|T~/society/unrest...|                null|  15850|\n",
      "|https://www.whec....|Travel advisory i...|C~Wayne County, N...|                null|   1927|\n",
      "|http://www.nola.c...|Travel agency own...|T~/art and entert...|                null|   6976|\n",
      "|https://www.democ...|Travel agent face...|C~Travel agency|2...|                null|   1971|\n",
      "|https://www.jsonl...|Travel agents and...|                null|                null|   2447|\n",
      "|http://www.chicag...|Travel agents: Ho...|C~Financial advis...|                null|    285|\n",
      "|http://www.al.com...|Travel alert issu...|                null|                null|     89|\n",
      "|http://www.khou.c...|Travel alert: 8 b...|T~/travel/travel ...|https://media.kho...|  21494|\n",
      "|https://clark.com...|Travel alert: Ala...|C~Alaska|49590|T^...|                null|    596|\n",
      "|https://clark.com...|Travel alert: Cla...|E~Kayak|66|U^^Com...|                null|   7862|\n",
      "+--------------------+--------------------+--------------------+--------------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"url\", \"title\", \"terms\", \"imageUrl\", \"traffic\").show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- articleIds: string (nullable = true)\n",
      " |-- countryCode: string (nullable = true)\n",
      " |-- createTime: string (nullable = true)\n",
      " |-- dailyTraffic: string (nullable = true)\n",
      " |-- day_count: string (nullable = true)\n",
      " |-- entities: string (nullable = true)\n",
      " |-- first_level_taxonomy: string (nullable = true)\n",
      " |-- imageUrl: string (nullable = true)\n",
      " |-- original_url: string (nullable = true)\n",
      " |-- publisherIds: string (nullable = true)\n",
      " |-- taxonomy: string (nullable = true)\n",
      " |-- terms: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- title_desc: string (nullable = true)\n",
      " |-- traffic: long (nullable = true)\n",
      " |-- url: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "from taboola.common.datasethelper.document_reader import DocumentReader\n",
    "\n",
    "\n",
    "def datetime_stamp():\n",
    "    dt = datetime.datetime.now()\n",
    "    return dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "\n",
    "def print_dt_stamped(value):\n",
    "    print datetime_stamp() + \": \" + value\n",
    "\n",
    "\n",
    "def load_train_docs(lines_file_dir):\n",
    "    document_reader = DocumentReader(lines_file_dir, header_skip=0, batch_size=10000, max_words=None, shuffle=False,\n",
    "                                     min_words=None).open_reader()\n",
    "    if document_reader is None:\n",
    "        raise IOError('Failed reading documents from train_file_dir {}.'.format(lines_file_dir))\n",
    "    doc_counts = 0\n",
    "    docs = []\n",
    "    while not document_reader.is_eof():\n",
    "        doc_tags, documents, _ = document_reader.get_batch()\n",
    "        if not doc_tags:\n",
    "            break\n",
    "        for i, doc_tag in enumerate(doc_tags):\n",
    "            words = ' '.join(documents[i][1])\n",
    "            docs.append(words)\n",
    "        doc_counts += len(doc_tags)\n",
    "        print_dt_stamped(\"documents read: \" + str(doc_counts) + \", first index: \" + str(doc_tags[0][0]))\n",
    "    document_reader.close_reader()\n",
    "    return docs\n",
    "\n",
    "train_docs = load_train_docs(\"/Users/jun.x/devfiles/topic_disco/20180323_106/all/StepLines__nocontent_v2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for article in articles[:10]:\n",
    "    print article.get_url()\n",
    "for doc in train_docs[:10]:\n",
    "    print str(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch.helpers import bulk\n",
    "\n",
    "def index_articles(es_endpoint, index_name, articles, train_docs):\n",
    "\n",
    "    es = Elasticsearch(hosts=[es_endpoint], timeout=5000)\n",
    "    \n",
    "    count = 0\n",
    "    ACTIONS = []\n",
    "    for i, article in enumerate(articles):\n",
    "        action = {\n",
    "            \"_index\": index_name,\n",
    "            \"_type\": \"article\",\n",
    "            \"_source\": {\n",
    "                \"url\": article.get_url(),\n",
    "                \"title\": article.get_title(),\n",
    "                \"words\": train_docs[i],\n",
    "                \"image_url\": article.get_image_url(),\n",
    "                \"traffic\": article.get_traffic()\n",
    "            }\n",
    "        }\n",
    "        ACTIONS.append(action)\n",
    "        if (i > 0 and i % 10000 == 0):\n",
    "            print \"Indexing \" + str(len(ACTIONS)) + \"documents, i: \" + str(i)\n",
    "            success, _ = bulk(es, ACTIONS, index = index_name, raise_on_error = True)\n",
    "            count += success\n",
    "            ACTIONS = []\n",
    "\n",
    "    success, _ = bulk(es, ACTIONS, index = index_name, raise_on_error=True)\n",
    "    count += success\n",
    "    print(\"insert %s lines\" % count)\n",
    "\n",
    "index_articles(\"127.0.0.1:9200\", \"topic_disco_full\", articles, train_docs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
